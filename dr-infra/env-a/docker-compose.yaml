############################
# GRUPO 1: Jenkins e Welcome
############################
services:

  jenkins:
    container_name: jenkins
    build:
      context: .
      dockerfile: Dockerfile-jenkins
    ports:
      - "10000:8080"
    environment:
      FLUENTD_HOST: fluentd
      FLUENTD_PORT: 24224
      TENANT: "jenkins"
      ACCESS_KEY: ${JENKINS_ACCESS_KEY}
      SECRET_KEY: ${JENKINS_SECRET_KEY}
    volumes:
      - jenkins_home:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    secrets:
      - jenkins-admin-password
    networks:
      - jenkins_nw
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:8080/login || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 8g
          cpus: "2"
        reservations:
          memory: 4g
          cpus: "1"
    restart: unless-stopped

##########################
# GRUPO 2: Dagster stack
##########################
  dagster-webserver:
    build:
      context: .
      dockerfile: Dockerfile-dagster
    image: dagster-webserver:local
    container_name: dagster-webserver
    ports:
      - "3005:3000"
    volumes:
      - ./dagster:/opt/dagster/app
      - ./dagster/dagster_home:/opt/dagster/dagster_home
    environment:
      DAGSTER_HOME: /opt/dagster/dagster_home
      PYTHONPATH: /opt/dagster/app
      SLACK_API_TOKEN: ${SLACK_API_TOKEN}
      SLACK_CHANNEL: "#alertas-dagster"
      AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_KEY}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_TRACKING_URI: http://mlflow:5000
    depends_on:
      - dagster-daemon
      - mlflow
      - minio
      - postgres
    networks:
      - jenkins_nw
    command: dagster-webserver -h 0.0.0.0 -p 3000

  dagster-daemon:
    build:
      context: .
      dockerfile: Dockerfile-dagster
    image: dagster-webserver:local
    container_name: dagster-daemon
    volumes:
      - ./dagster:/opt/dagster/app
      - ./dagster/dagster_home:/opt/dagster/dagster_home
    environment:
      DAGSTER_HOME: /opt/dagster/dagster_home
      PYTHONPATH: /opt/dagster/app
      SLACK_API_TOKEN: ${SLACK_API_TOKEN}
      SLACK_CHANNEL: "#alertas-dagster"
      AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_KEY}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      MLFLOW_TRACKING_URI: http://mlflow:5000
    depends_on:
      - mlflow
      - minio
      - postgres
    networks:
      - jenkins_nw
    command: dagster-daemon run


############################
# GRUPO 3: MinIO e MLflow
############################
  minio:
    image: minio/minio:RELEASE.2020-08-08T04-50-06Z
    container_name: minio
    ports:
      - "9000:9000"
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
    entrypoint: sh
    command: -c 'mkdir -p /data/cd4ml-ml-flow-bucket && /usr/bin/minio server /data'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    volumes:
      - minio-storage:/data
    networks:
      - jenkins_nw

  mlflow:
    container_name: mlflow
    build:
      context: .
      dockerfile: Dockerfile-mlflow
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_KEY}
      MLFLOW_TRACKING_URI: http://mlflow:5000
      BACKEND_STORE_URI: postgresql+psycopg2://agro_user:agro_password@postgres:5432/brain_agro
      GUNICORN_CMD_ARGS: "--timeout 300 --workers 4 --bind 0.0.0.0:5000 --log-level debug"
    ports:
      - "12000:5000"
    networks:
      - jenkins_nw
    volumes:
      - mlflow-storage:/mnt/mlflow
    depends_on:
      - minio
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/2.0/mlflow/experiments/list"]
      interval: 20s
      timeout: 10s
      retries: 10
    command: >
      mlflow server --backend-store-uri postgresql+psycopg2://agro_user:agro_password@postgres:5432/brain_agro --default-artifact-root s3://cd4ml-ml-flow-bucket/ --host 0.0.0.0 --port 5000
 
#########################
# GRUPO 4: Airflow stack
#########################
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5433:5432"
    volumes:
      - ./postgres-init-scripts:/docker-entrypoint-initdb.d:ro
      - postgres_data:/var/lib/postgresql/data
    networks:
      - jenkins_nw
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-webserver:
    image: apache/airflow:2.6.1
    restart: always
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://agro_user:agro_password@postgres:5432/brain_agro
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
    ports:
      - "8083:8080"
    command: >
      bash -c "
        airflow db upgrade &&
        airflow users create --username admin --firstname Admin --lastname Admin --role Admin --email admin@admin.com --password admin &&
        airflow webserver
      "
    networks:
      - jenkins_nw

  airflow-scheduler:
    image: apache/airflow:2.6.1
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://agro_user:agro_password@postgres:5432/brain_agro
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
    command: scheduler
    networks:
      - jenkins_nw

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "8081:80"
    networks:
      - jenkins_nw
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-s", "http://localhost:80 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

#########################
# GRUPO 5: Logging e Dados
#########################
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.6.0
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - bootstrap.memory_lock=true
      - http.port=9200
      - http.host=0.0.0.0
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - discovery.type=single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - jenkins_nw

  kib01:
    image: docker.elastic.co/kibana/kibana:7.6.0
    container_name: kib01
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://es01:9200
      ELASTICSEARCH_HOSTS: http://es01:9200
    networks:
      - jenkins_nw
    depends_on:
      - es01

  fluentd:
    image: ericnaglertw/cd4ml-fluentd:1
    container_name: fluentd
    volumes:
      - ./fluentd/conf:/fluentd/etc
    ports:
      - "24224:24224"
    networks:
      - jenkins_nw
    depends_on:
      - es01

  load_data:
    build:
      context: .
      dockerfile: load_data/Dockerfile
    container_name: load_data
    volumes:
      - ./data:/app/data
      - ./scripts:/app/scripts
    networks:
      - jenkins_nw
    depends_on:
      postgres:
        condition: service_healthy
    entrypoint: ["sh", "-c", "while ! pg_isready -h postgres -U ${POSTGRES_USER}; do sleep 1; done; python /app/scripts/load_data.py"]
    deploy:
      resources:
        limits:
          memory: 4g

#########################
# GRUPO 6: Dev tools
#########################
  dev:
    container_name: dev
    image: jupyter/minimal-notebook:54462805efcb
    environment:
      - JUPYTER_ENABLE_LAB=yes
    ports:
      - "8888:8888"
    entrypoint: "start.sh"
    command: "jupyter lab --LabApp.token=''"
    volumes:
      - .:/home/jovyan/
    networks:
      - jenkins_nw

  cd4ml-api:
    build:
      context: ./cd4ml-api
    container_name: cd4ml-api
    ports:
      - "8000:8000"
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      AWS_ACCESS_KEY_ID: ${MINIO_ACCESS_KEY}
      AWS_SECRET_ACCESS_KEY: ${MINIO_SECRET_KEY}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    depends_on:
      - mlflow
    networks:
      - jenkins_nw

  interface:
    build:
      context: ./cd4ml-interface
    container_name: interface
    ports:
      - "11001:8000"
    restart: always
    depends_on:
      - mlflow
      - dagster-webserver
      - minio
      - jenkins
    volumes:
      - ./cd4ml-interface:/app
    working_dir: /app
    environment:
      - FLASK_ENV=development
      - PYTHONUNBUFFERED=1
      - TZ=America/Sao_Paulo
      - FLASK_APP=main.py
    command: python main.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
#########################
# FILAS Kafka e Zookeeper
#########################
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - jenkins_nw

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - jenkins_nw

#########################
# Volumes, Redes e Segredos
#########################
volumes:
  jenkins_home:
  data01:
  minio-storage:
  mlflow-storage:
  postgres_data:

networks:
  jenkins_nw:
    driver: bridge

secrets:
  jenkins-admin-password:
    file: ./jenkins/jenkins-admin-password.txt
